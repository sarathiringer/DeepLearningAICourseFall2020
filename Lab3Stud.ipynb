{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhoQ0WE77laV"
   },
   "source": [
    "# Deep learning and AI methods\n",
    "## Session 3: Feedforward Neural Network and cloth images\n",
    "* Instructor: [Krzysztof Podgorski](https://krys.neocities.org),  [Statistics, Lund University, LUSEM](https://www.stat.lu.se/)\n",
    "* For more information visit the [CANVAS class website](https://canvas.education.lu.se/courses/1712).\n",
    "\n",
    "In this session we learn some basic about *TensorFlow* and *Keras* by solving an example of immage recognition problem. Note that the code is not necessarily complete so it may not be enough just to run the code cells and somme your own programing may be needed on some occasions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "## Project 1 Building neural networks for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "This project trains a neural network model to classify images of clothing, like sneakers and shirts. It's okay if you don't understand all the details; this is a fast-paced overview of a complete TensorFlow program with the details explained as you go.\n",
    "\n",
    "This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Importing tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just something I need to set up to make fitting work without kernel dying\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images_raw, train_labels), (test_images_raw, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is a repetition from the previous lab to obtain the split of the data for cross-validation and pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# Scaling the data\n",
    "train_images = train_images_raw / 255.0\n",
    "test_images = test_images_raw / 255.0\n",
    "\n",
    "# Shuffle and rearrange data\n",
    "perm = np.random.permutation(60000)\n",
    "rearr = perm.reshape(10, 6000)\n",
    "\n",
    "# Create cross validation set\n",
    "CV_images = train_images[rearr]\n",
    "CV_labels = train_labels[rearr]\n",
    "print(len(CV_images[0]))\n",
    "\n",
    "# commenting this out so as not to scale once more\n",
    "# CV_images = CV_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.7 ms, sys: 14.3 ms, total: 74.1 ms\n",
      "Wall time: 91.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Prepare cross validation set 1\n",
    "CVin = [list(rearr[0]), list(rearr[1])]\n",
    "for k in range(8):\n",
    "    CVin[1] = CVin[1] + list(rearr[k+2]%10)\n",
    "CVin = [CVin]\n",
    "\n",
    "# Same for the rest of the sets\n",
    "for i in range(9):\n",
    "    C = [list(rearr[i+1]), list(rearr[(i+2)%10])]\n",
    "    for k in range(8):\n",
    "        C[1] = C[1] + list(rearr[(i+3+k)%10])\n",
    "    CVin = CVin + [C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59veuiEZCaW4"
   },
   "source": [
    "### Build the model\n",
    "\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "#### Set up the layers\n",
    "\n",
    "The basic building block of a neural network is the *layer*. Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as `tf.keras.layers.Dense`, have parameters that are learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "# Set up the model using two hidden layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
    "\n",
    "After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are densely connected, or fully connected, neural layers. The first `Dense` layer has 128 nodes (or neurons). The second (and last) layer is a 10-node *softmax* layer that returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.\n",
    "\n",
    "### Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n",
    "\n",
    "* *Loss function* —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "* *Optimizer* —This is how the model is updated based on the data it sees and its loss function.\n",
    "* *Metrics* —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# Set up training 'instructions' for the model\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "### Task 1: Train the model\n",
    "\n",
    "Check the basic info about the model using `model.summary()`. How many parameters is there in the model? How could you count without using this function? Training the neural network model requires the following steps:\n",
    "\n",
    "1. Feed the training data to the model. In this example, the training data is in the `train_images` and `train_labels` arrays.\n",
    "2. The model learns to associate images and labels.\n",
    "3. You ask the model to make predictions about a test set—in this example, the `test_images` array. Verify that the predictions match the labels from the `test_labels` array.\n",
    "\n",
    "To start training,  call the `model.fit` method — it is so called because it \"fits\" the model to the training data.\n",
    "\n",
    "Please, perform fitting the model and analyze its performance. Compare the reported accuracy on the training data to the one on the testing data set. For the latter, use `model.evaluate(test_images,  test_labels, verbose=2)`. Note that the algorithms also give the loss function values. \n",
    "\n",
    "Compare the results with the ones obtained by the MGaussianLE method from the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_55 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check model setup\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 247us/sample - loss: 0.4920 - acc: 0.8253\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 0.3693 - acc: 0.8662\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.3337 - acc: 0.8778\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 266us/sample - loss: 0.3085 - acc: 0.8873\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.2897 - acc: 0.8934\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.2768 - acc: 0.8971\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.2634 - acc: 0.9026\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 302us/sample - loss: 0.2544 - acc: 0.9047\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 291us/sample - loss: 0.2443 - acc: 0.9095\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.2347 - acc: 0.9112\n",
      "CPU times: user 3min 44s, sys: 59.5 s, total: 4min 43s\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0b0314240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_images, train_labels, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEw4bZgGCaXB"
   },
   "source": [
    "#### Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VflXLEeECaXC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.3330 - acc: 0.8841\n",
      "\n",
      "Test accuracy: 0.8841\n",
      "\n",
      "Error rate: 0.11589998006820679\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test data\n",
    "test_loss_, test_acc = model.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nError rate:', 1 - test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: To start with, we can note that it's already performing quite a bit better then the ML classifier we built in lab 2 (which had an error rate around 30 %)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "\n",
    "Consider five other designs of neural networks that you would test on the above data set. In your design change the number of layers and the number of neuron per layer but preserve the total number of neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "I'll now build five more models, in which I'll slightly change some of the model settings. We can call this changing the model architecture, if we want to use big words. Summary of how I'll change the models:\n",
    "\n",
    "* Model1: Add one extra 'relu' activaion hidden layer\n",
    "* Model2: Add three extra 'relu' activation hidden layers and change their number of nodes to 32\n",
    "* Model3: Change activation in hidden later in original model to sigmoid\n",
    "* Model4: Add three layers with 'relu' and use different number of nodes per layer\n",
    "* Model5: Change the number of nodes in the original model to only 64\n",
    "\n",
    "Not that I'm not actually fitting them as that seems to be the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "\n",
    "def define_compile_model1(dim = 28):\n",
    "    # Architecture\n",
    "    model1 = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (dim, dim)),\n",
    "        keras.layers.Dense(128, activation = 'relu'),\n",
    "        keras.layers.Dense(128, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    # Training settings\n",
    "    model1.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "model1 = define_compile_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "def define_compile_model2(dim = 28):\n",
    "    # Architechture\n",
    "    model2 = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (dim, dim)),\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    # Training settings\n",
    "    model2.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    return model2\n",
    "\n",
    "model2 = define_compile_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "\n",
    "def define_compile_model3(dim = 28):\n",
    "    # Architechture\n",
    "    model3 = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (dim, dim)),\n",
    "        keras.layers.Dense(128, activation = 'sigmoid'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    # Training settings\n",
    "    model3.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    \n",
    "    return model3\n",
    "\n",
    "model3 = define_compile_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4\n",
    "\n",
    "def define_compile_model4(dim = 28):\n",
    "    # Architechture\n",
    "    model4 = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (dim, dim)),\n",
    "        keras.layers.Dense(392, activation = 'relu'),\n",
    "        keras.layers.Dense(98, activation = 'relu'),\n",
    "        keras.layers.Dense(128, activation = 'relu'),\n",
    "        keras.layers.Dense(20, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    # Training settings\n",
    "    model4.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "    \n",
    "    return model4\n",
    "\n",
    "model4 = define_compile_model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "\n",
    "def define_compile_model5(dim = 28):\n",
    "    # Architechture\n",
    "    model5 = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (dim, dim)),\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    # Training settings\n",
    "    model5.compile(optimizer = 'adam',\n",
    "                  loss = 'sparse_categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model5\n",
    "\n",
    "model5 = define_compile_model5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_55 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_79 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_89 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 28,618\n",
      "Trainable params: 28,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_90 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_91 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 98)                38514     \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 128)               12672     \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 361,696\n",
      "Trainable params: 361,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_92 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:\n",
    "\n",
    "Use the 10 fold cross validation method to investigate the performance of the networks designed by you as well as the the one that was originally trained above (for the total of six networks). Select the one that based on the performed cross validation worked best. It can be computationally (and thus timewise) costly operation. Test the approach with smaller sizes to assess the time needed. You may reduce the size of the data if you see that your computers will not handle the task within reasonable time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    Arguments:\n",
      "        x: Input data. It could be:\n",
      "          - A Numpy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "          - A TensorFlow tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "          - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "          - A `tf.data` dataset. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "            or `(inputs, targets, sample weights)`.\n",
      "        y: Target data. Like the input data `x`,\n",
      "          it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "          It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "          tensor targets, or inversely). If `x` is a dataset, generator,\n",
      "          or `keras.utils.Sequence` instance, `y` should\n",
      "          not be specified (since targets will be obtained from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, datasets,\n",
      "            generators, or `keras.utils.Sequence` instances (since they generate\n",
      "            batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            Note that the progress bar is not particularly useful when\n",
      "            logged to a file, so verbose=2 is recommended when not running\n",
      "            interactively (eg, in a production environment).\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `tf.keras.callbacks`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling. This argument is\n",
      "            not supported when `x` is a dataset, generator or\n",
      "           `keras.utils.Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "              - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "              - dataset\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` must be provided.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch').\n",
      "            'batch' is a special option for dealing with the\n",
      "            limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "            Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            In this case you should make sure to specify\n",
      "            `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      "            supported when `x` is a dataset, generator, or\n",
      "           `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      "            as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined. If x is a\n",
      "            `tf.data` dataset, and 'steps_per_epoch'\n",
      "            is None, the epoch will run until the input dataset is exhausted.\n",
      "            This argument is not supported with array inputs.\n",
      "        validation_steps: Only relevant if `validation_data` is provided and\n",
      "            is a `tf.data` dataset. Total number of steps (batches of\n",
      "            samples) to draw before stopping when performing validation\n",
      "            at the end of every epoch. If validation_data is a `tf.data` dataset\n",
      "            and 'validation_steps' is None, validation\n",
      "            will run until the `validation_data` dataset is exhausted.\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      "            If an integer, specifies how many training epochs to run before a\n",
      "            new validation run is performed, e.g. `validation_freq=2` runs\n",
      "            validation every 2 epochs. If a Container, specifies the epochs on\n",
      "            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "            validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "        **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    Raises:\n",
      "        RuntimeError: If the model was never compiled.\n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.0991 - acc: 0.9686\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 27s 499us/sample - loss: 0.0600 - acc: 0.9789\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 250us/sample - loss: 0.0502 - acc: 0.9820\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.0459 - acc: 0.9831\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.0430 - acc: 0.9844\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 250us/sample - loss: 0.0390 - acc: 0.9851\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.0368 - acc: 0.9859\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 238us/sample - loss: 0.0351 - acc: 0.9865\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.0330 - acc: 0.9878\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 281us/sample - loss: 0.0314 - acc: 0.9883\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 23s 431us/sample - loss: 0.5058 - acc: 0.8246\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 22s 409us/sample - loss: 0.3765 - acc: 0.8652\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 15s 275us/sample - loss: 0.3377 - acc: 0.8768\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.3119 - acc: 0.8842\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.2944 - acc: 0.8923\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 245us/sample - loss: 0.2786 - acc: 0.8973\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.2683 - acc: 0.8998\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 15s 280us/sample - loss: 0.2575 - acc: 0.9038\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 227us/sample - loss: 0.2467 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.2390 - acc: 0.9104\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 24s 450us/sample - loss: 0.5043 - acc: 0.8238\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 17s 320us/sample - loss: 0.3811 - acc: 0.8631\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 251us/sample - loss: 0.3433 - acc: 0.8753\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.3157 - acc: 0.8843\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 16s 295us/sample - loss: 0.3019 - acc: 0.8894\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 19s 355us/sample - loss: 0.2834 - acc: 0.8955 - loss: 0.2835 - a\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 22s 403us/sample - loss: 0.2716 - acc: 0.8991\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.2609 - acc: 0.9031\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.2517 - acc: 0.9066\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 19s 348us/sample - loss: 0.2394 - acc: 0.9109\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 283us/sample - loss: 0.5068 - acc: 0.8215\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.3837 - acc: 0.8623\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 16s 303us/sample - loss: 0.3418 - acc: 0.8767\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 233us/sample - loss: 0.3174 - acc: 0.8838\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.2984 - acc: 0.8898\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 17s 310us/sample - loss: 0.2857 - acc: 0.8946\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 263us/sample - loss: 0.2719 - acc: 0.8999\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 251us/sample - loss: 0.2581 - acc: 0.9043\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.2500 - acc: 0.9074\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 21s 381us/sample - loss: 0.2429 - acc: 0.9084\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 29s 531us/sample - loss: 0.5036 - acc: 0.8228\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 264us/sample - loss: 0.3787 - acc: 0.8638\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 24s 438us/sample - loss: 0.3397 - acc: 0.8761\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 23s 419us/sample - loss: 0.3148 - acc: 0.8848\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 14s 253us/sample - loss: 0.2963 - acc: 0.8906\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 268us/sample - loss: 0.2834 - acc: 0.8950\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 16s 289us/sample - loss: 0.2707 - acc: 0.8996\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.2587 - acc: 0.9036\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 15s 277us/sample - loss: 0.2475 - acc: 0.9081\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 16s 296us/sample - loss: 0.2402 - acc: 0.9090\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 28s 523us/sample - loss: 0.5054 - acc: 0.8230\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 18s 328us/sample - loss: 0.3791 - acc: 0.8628\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 23s 431us/sample - loss: 0.3380 - acc: 0.8769\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.3140 - acc: 0.8841\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.2955 - acc: 0.8916\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 10s 182us/sample - loss: 0.2808 - acc: 0.8966\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 0.2682 - acc: 0.8998\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.2594 - acc: 0.9030\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 10s 189us/sample - loss: 0.2480 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.2384 - acc: 0.9109\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.5062 - acc: 0.8225\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 25s 461us/sample - loss: 0.3844 - acc: 0.8599\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 19s 349us/sample - loss: 0.3417 - acc: 0.8749\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 19s 351us/sample - loss: 0.3181 - acc: 0.8830\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 21s 390us/sample - loss: 0.2986 - acc: 0.8901\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.2852 - acc: 0.8941\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 202us/sample - loss: 0.2690 - acc: 0.8997\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.2582 - acc: 0.9040\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.2495 - acc: 0.9068\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.2412 - acc: 0.9093\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.5118 - acc: 0.8204\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.3827 - acc: 0.8627\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.3413 - acc: 0.8758\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 207us/sample - loss: 0.3130 - acc: 0.8857\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 18s 328us/sample - loss: 0.2995 - acc: 0.8888\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.2827 - acc: 0.8963\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.2724 - acc: 0.8978\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 22s 401us/sample - loss: 0.2600 - acc: 0.9039\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.2497 - acc: 0.9077\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.2433 - acc: 0.9092\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 281us/sample - loss: 0.5079 - acc: 0.8227\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.3805 - acc: 0.8643\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 215us/sample - loss: 0.3411 - acc: 0.8755\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.3169 - acc: 0.8836\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.2977 - acc: 0.8904\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 16s 300us/sample - loss: 0.2830 - acc: 0.8951\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.2702 - acc: 0.8999\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 17s 316us/sample - loss: 0.2578 - acc: 0.9041\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 29s 532us/sample - loss: 0.2501 - acc: 0.9068\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 21s 384us/sample - loss: 0.2423 - acc: 0.9100\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 18s 335us/sample - loss: 0.5087 - acc: 0.8210\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 17s 314us/sample - loss: 0.3775 - acc: 0.8641\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.3384 - acc: 0.8771\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 17s 313us/sample - loss: 0.3113 - acc: 0.8856\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 20s 361us/sample - loss: 0.2954 - acc: 0.8906\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 275us/sample - loss: 0.2814 - acc: 0.8966\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.2668 - acc: 0.9025\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 17s 314us/sample - loss: 0.2571 - acc: 0.9051\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.2480 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 258us/sample - loss: 0.2375 - acc: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# Cross validation on original model\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model \n",
    "    \n",
    "    # Redefine model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (28, 28)),\n",
    "        keras.layers.Dense(128, activation = 'relu'),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    # Recompile model\n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = 'sparse_categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8856999\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model = np.mean(test_acc_list)\n",
    "print('Accuracy:', CV_accuracy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 22s 412us/sample - loss: 0.0963 - acc: 0.9675\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 250us/sample - loss: 0.0600 - acc: 0.9781\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.0519 - acc: 0.9806\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.0465 - acc: 0.9826\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 269us/sample - loss: 0.0437 - acc: 0.9837\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 16s 302us/sample - loss: 0.0402 - acc: 0.9847\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.0380 - acc: 0.9858\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.0353 - acc: 0.9864\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.0338 - acc: 0.9872\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 21s 392us/sample - loss: 0.0325 - acc: 0.9876\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 17s 307us/sample - loss: 0.4972 - acc: 0.8216\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 18s 326us/sample - loss: 0.3698 - acc: 0.8647\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.3338 - acc: 0.8747\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 24s 450us/sample - loss: 0.3094 - acc: 0.8851\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 32s 596us/sample - loss: 0.2897 - acc: 0.8929\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 16s 288us/sample - loss: 0.2764 - acc: 0.8963\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 265us/sample - loss: 0.2620 - acc: 0.9001\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 268us/sample - loss: 0.2528 - acc: 0.9039\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 403us/sample - loss: 0.2406 - acc: 0.9089\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 16s 293us/sample - loss: 0.2308 - acc: 0.9123\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 17s 307us/sample - loss: 0.4999 - acc: 0.8201\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 238us/sample - loss: 0.3704 - acc: 0.8647\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.3347 - acc: 0.8759\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 248us/sample - loss: 0.3111 - acc: 0.8836\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.2952 - acc: 0.8905\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.2797 - acc: 0.8946\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.2664 - acc: 0.9004\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 235us/sample - loss: 0.2531 - acc: 0.9044\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.2448 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.2344 - acc: 0.9116\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.4988 - acc: 0.8209\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.3704 - acc: 0.8635\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.3349 - acc: 0.8776\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.3102 - acc: 0.8864\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.2934 - acc: 0.8917\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.2768 - acc: 0.8969\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.2657 - acc: 0.9003\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2542 - acc: 0.9041\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2461 - acc: 0.9077\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.2350 - acc: 0.9114\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.4948 - acc: 0.8251\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.3692 - acc: 0.8642\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.3346 - acc: 0.8769\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.3094 - acc: 0.8858\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.2922 - acc: 0.8913\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.2797 - acc: 0.8946\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.2634 - acc: 0.9007\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2515 - acc: 0.9050\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.2439 - acc: 0.9076\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.2307 - acc: 0.9130\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 273us/sample - loss: 0.4983 - acc: 0.8200\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 15s 275us/sample - loss: 0.3667 - acc: 0.8647\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.3298 - acc: 0.8771\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 28s 517us/sample - loss: 0.3070 - acc: 0.8864\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 23s 426us/sample - loss: 0.2895 - acc: 0.8919\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.2744 - acc: 0.8956\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.2610 - acc: 0.9010\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.2512 - acc: 0.9043\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 16s 287us/sample - loss: 0.2411 - acc: 0.9075\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.2322 - acc: 0.9111\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 275us/sample - loss: 0.4996 - acc: 0.8202\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.3714 - acc: 0.8656\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 263us/sample - loss: 0.3339 - acc: 0.8781\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 262us/sample - loss: 0.3119 - acc: 0.8856\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 271us/sample - loss: 0.2920 - acc: 0.8916\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2772 - acc: 0.8951\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.2650 - acc: 0.9007\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 263us/sample - loss: 0.2546 - acc: 0.9034\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 15s 278us/sample - loss: 0.2434 - acc: 0.9086\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.2386 - acc: 0.9108\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 276us/sample - loss: 0.4959 - acc: 0.8220\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 15s 270us/sample - loss: 0.3713 - acc: 0.8642\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.3355 - acc: 0.8769\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 18s 338us/sample - loss: 0.3128 - acc: 0.8846\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.2967 - acc: 0.8897\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.2772 - acc: 0.8969\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.2662 - acc: 0.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.2542 - acc: 0.9044\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.2416 - acc: 0.9090\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 235us/sample - loss: 0.2371 - acc: 0.9100\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.4867 - acc: 0.8250\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.3639 - acc: 0.8674\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 250us/sample - loss: 0.3300 - acc: 0.8780\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.3085 - acc: 0.8853\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.2902 - acc: 0.8922\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 250us/sample - loss: 0.2750 - acc: 0.8972\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2616 - acc: 0.9014\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.2530 - acc: 0.9046\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2409 - acc: 0.9088\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 248us/sample - loss: 0.2334 - acc: 0.9124\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.4962 - acc: 0.8221\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 258us/sample - loss: 0.3664 - acc: 0.8651\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.3341 - acc: 0.8756\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 21s 384us/sample - loss: 0.3102 - acc: 0.8855\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 14s 253us/sample - loss: 0.2909 - acc: 0.8931\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 283us/sample - loss: 0.2751 - acc: 0.8976\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.2608 - acc: 0.9028\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.2526 - acc: 0.9058\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.2417 - acc: 0.9089\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 16s 303us/sample - loss: 0.2338 - acc: 0.9106\n"
     ]
    }
   ],
   "source": [
    "# Model1\n",
    "\n",
    "test_loss_list_model1 = []\n",
    "test_acc_list_model1 = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model1 \n",
    "    \n",
    "    # Redefine and recompile model\n",
    "    model1 = define_compile_model1()\n",
    "    \n",
    "    # Fit model\n",
    "    model1.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model1.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list_model1.append(test_loss)\n",
    "    test_acc_list_model1.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8849667\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model1 = np.mean(test_acc_list_model1)\n",
    "print('Accuracy:', CV_accuracy_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.1321 - acc: 0.9605\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.0660 - acc: 0.9761\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 9s 173us/sample - loss: 0.0572 - acc: 0.9792\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 184us/sample - loss: 0.0513 - acc: 0.9809\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 10s 179us/sample - loss: 0.0487 - acc: 0.9818\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 9s 173us/sample - loss: 0.0457 - acc: 0.9830\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 10s 185us/sample - loss: 0.0427 - acc: 0.9842\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 187us/sample - loss: 0.0425 - acc: 0.9841\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 10s 190us/sample - loss: 0.0403 - acc: 0.9849\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.0385 - acc: 0.9857\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.6007 - acc: 0.7854\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.4178 - acc: 0.8509\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s 183us/sample - loss: 0.3777 - acc: 0.8622\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.3545 - acc: 0.8688\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.3358 - acc: 0.8764\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.3217 - acc: 0.8814\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.3124 - acc: 0.8831\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 184us/sample - loss: 0.3012 - acc: 0.8882\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2957 - acc: 0.8897\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.2887 - acc: 0.8929\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.5768 - acc: 0.7975\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.4087 - acc: 0.8523\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 11s 205us/sample - loss: 0.3734 - acc: 0.8633\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 0.3551 - acc: 0.8687\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 0.3372 - acc: 0.8743\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 0.3248 - acc: 0.8801\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 0.3152 - acc: 0.8828\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 17s 312us/sample - loss: 0.3037 - acc: 0.8870\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 21s 382us/sample - loss: 0.2969 - acc: 0.8897\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.2874 - acc: 0.8921\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.5926 - acc: 0.7913\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.4209 - acc: 0.8494\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.3806 - acc: 0.8615\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 0.3594 - acc: 0.8692\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.3427 - acc: 0.8738 - loss: 0.343\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.3293 - acc: 0.8794\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 213us/sample - loss: 0.3199 - acc: 0.8827\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 191us/sample - loss: 0.3102 - acc: 0.8852\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 0.3042 - acc: 0.8881\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.2952 - acc: 0.8911\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 205us/sample - loss: 0.5913 - acc: 0.7880\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 199us/sample - loss: 0.4143 - acc: 0.8509\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 0.3753 - acc: 0.8624 - loss: 0.3736 -\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 200us/sample - loss: 0.3536 - acc: 0.8714\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.3360 - acc: 0.8752\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.3223 - acc: 0.8825\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.3142 - acc: 0.8828\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 0.3022 - acc: 0.8859\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.2973 - acc: 0.8880\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.2893 - acc: 0.8910\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.5709 - acc: 0.7940\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 0.4129 - acc: 0.8481\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.3749 - acc: 0.8629\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 0.3505 - acc: 0.8691\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 204us/sample - loss: 0.3322 - acc: 0.8775\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 207us/sample - loss: 0.3184 - acc: 0.8830\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 202us/sample - loss: 0.3086 - acc: 0.8854\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 199us/sample - loss: 0.2999 - acc: 0.8883\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 197us/sample - loss: 0.2881 - acc: 0.8928\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.2819 - acc: 0.8947\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.5855 - acc: 0.7944\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 0.4112 - acc: 0.8519\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.3720 - acc: 0.8645\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.3504 - acc: 0.8710\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 215us/sample - loss: 0.3332 - acc: 0.8791\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.3183 - acc: 0.8821\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 207us/sample - loss: 0.3089 - acc: 0.8864\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 0.3010 - acc: 0.8896\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 199us/sample - loss: 0.2931 - acc: 0.8911\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 11s 205us/sample - loss: 0.2856 - acc: 0.8934\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.5997 - acc: 0.7851\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.4211 - acc: 0.8472\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.3828 - acc: 0.8614\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.3599 - acc: 0.8680\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.3418 - acc: 0.8744\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.3299 - acc: 0.8792\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 199us/sample - loss: 0.3194 - acc: 0.8826\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 188us/sample - loss: 0.3099 - acc: 0.8854\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 17s 306us/sample - loss: 0.3030 - acc: 0.8878\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.2958 - acc: 0.8905\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 11s 209us/sample - loss: 0.5870 - acc: 0.7924\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.4125 - acc: 0.8514\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s 185us/sample - loss: 0.3764 - acc: 0.8625\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.3535 - acc: 0.8697\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 210us/sample - loss: 0.3397 - acc: 0.8762\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.3257 - acc: 0.8792\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 198us/sample - loss: 0.3172 - acc: 0.8826\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 0.3046 - acc: 0.8876\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 10s 187us/sample - loss: 0.2977 - acc: 0.8893\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 0.2899 - acc: 0.8933\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 238us/sample - loss: 0.5802 - acc: 0.7951\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 205us/sample - loss: 0.4053 - acc: 0.8553\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.3694 - acc: 0.8649\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s 203us/sample - loss: 0.3480 - acc: 0.8710\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 11s 204us/sample - loss: 0.3317 - acc: 0.8782\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.3194 - acc: 0.8822\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 211us/sample - loss: 0.3088 - acc: 0.8856\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 200us/sample - loss: 0.2989 - acc: 0.8890\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 207us/sample - loss: 0.2930 - acc: 0.8918\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 11s 202us/sample - loss: 0.2840 - acc: 0.8936\n"
     ]
    }
   ],
   "source": [
    "# Model2\n",
    "\n",
    "test_loss_list_model2 = []\n",
    "test_acc_list_model2 = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model2 \n",
    "    \n",
    "    # Redefine and recompile model\n",
    "    model2 = define_compile_model2()\n",
    "    \n",
    "    # Fit model\n",
    "    model2.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model2.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list_model2.append(test_loss)\n",
    "    test_acc_list_model2.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8721167\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model2 = np.mean(test_acc_list_model2)\n",
    "print('Accuracy:', CV_accuracy_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 16s 299us/sample - loss: 0.1210 - acc: 0.9643\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 266us/sample - loss: 0.0593 - acc: 0.9787\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.0511 - acc: 0.9814\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 239us/sample - loss: 0.0456 - acc: 0.9832\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.0419 - acc: 0.9844\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 266us/sample - loss: 0.0391 - acc: 0.9853\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 15s 271us/sample - loss: 0.0367 - acc: 0.9861\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 15s 273us/sample - loss: 0.0338 - acc: 0.9878\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.0324 - acc: 0.9882\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.0301 - acc: 0.9889\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 282us/sample - loss: 0.5565 - acc: 0.8107\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 17s 307us/sample - loss: 0.3999 - acc: 0.8550\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 15s 284us/sample - loss: 0.3628 - acc: 0.8696\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 15s 275us/sample - loss: 0.3371 - acc: 0.8787\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 276us/sample - loss: 0.3168 - acc: 0.8846\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 284us/sample - loss: 0.3018 - acc: 0.8899\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 251us/sample - loss: 0.2881 - acc: 0.8951\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 252us/sample - loss: 0.2760 - acc: 0.8977\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.2672 - acc: 0.9004\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.2561 - acc: 0.9060\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 280us/sample - loss: 0.5536 - acc: 0.8126\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 15s 271us/sample - loss: 0.3991 - acc: 0.8551\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.3607 - acc: 0.8706\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 266us/sample - loss: 0.3368 - acc: 0.8776\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.3177 - acc: 0.8841\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 279us/sample - loss: 0.3025 - acc: 0.8897\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 17s 315us/sample - loss: 0.2894 - acc: 0.8942\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.2784 - acc: 0.8977\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 263us/sample - loss: 0.2662 - acc: 0.9016\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.2579 - acc: 0.9050\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.5517 - acc: 0.8118\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 260us/sample - loss: 0.3988 - acc: 0.8560\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.3611 - acc: 0.8693\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 14s 257us/sample - loss: 0.3368 - acc: 0.8771\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 25s 458us/sample - loss: 0.3178 - acc: 0.8840\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 22s 402us/sample - loss: 0.3020 - acc: 0.8903\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 20s 371us/sample - loss: 0.2896 - acc: 0.8932\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 38s 700us/sample - loss: 0.2765 - acc: 0.8986\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 17s 307us/sample - loss: 0.2660 - acc: 0.9020\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 17s 324us/sample - loss: 0.2561 - acc: 0.9069\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 17s 323us/sample - loss: 0.5521 - acc: 0.8117\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 16s 304us/sample - loss: 0.3991 - acc: 0.8541\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 258us/sample - loss: 0.3616 - acc: 0.8693\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 21s 396us/sample - loss: 0.3361 - acc: 0.8779\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 16s 301us/sample - loss: 0.3176 - acc: 0.8841\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 23s 424us/sample - loss: 0.3018 - acc: 0.8892\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 21s 396us/sample - loss: 0.2887 - acc: 0.8956\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 21s 384us/sample - loss: 0.2769 - acc: 0.8980\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 18s 334us/sample - loss: 0.2662 - acc: 0.9011\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 285us/sample - loss: 0.2574 - acc: 0.9051\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.5498 - acc: 0.8122\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 266us/sample - loss: 0.3954 - acc: 0.8567\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 18s 328us/sample - loss: 0.3572 - acc: 0.8699\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 15s 278us/sample - loss: 0.3329 - acc: 0.8775\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.3120 - acc: 0.8861\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.2979 - acc: 0.8906\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 219us/sample - loss: 0.2848 - acc: 0.8942\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.2734 - acc: 0.8988\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 16s 289us/sample - loss: 0.2619 - acc: 0.9031\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 230us/sample - loss: 0.2540 - acc: 0.9049\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 283us/sample - loss: 0.5561 - acc: 0.8105\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 261us/sample - loss: 0.4008 - acc: 0.8552\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 266us/sample - loss: 0.3629 - acc: 0.8681 - loss: 0.3625 - \n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 16s 288us/sample - loss: 0.3369 - acc: 0.8778\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 271us/sample - loss: 0.3164 - acc: 0.8849\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.3011 - acc: 0.8903\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 16s 288us/sample - loss: 0.2864 - acc: 0.8948\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 253us/sample - loss: 0.2769 - acc: 0.8980\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 11s 204us/sample - loss: 0.2657 - acc: 0.9014\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 267us/sample - loss: 0.2554 - acc: 0.9058\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 19s 346us/sample - loss: 0.5522 - acc: 0.8112\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 262us/sample - loss: 0.3988 - acc: 0.8567\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 17s 312us/sample - loss: 0.3610 - acc: 0.8696\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.3352 - acc: 0.8787\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 269us/sample - loss: 0.3159 - acc: 0.8850\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 276us/sample - loss: 0.3000 - acc: 0.8905\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 17s 310us/sample - loss: 0.2881 - acc: 0.8947\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.2747 - acc: 0.8991\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.2641 - acc: 0.9030\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 272us/sample - loss: 0.2549 - acc: 0.9066\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 270us/sample - loss: 0.5559 - acc: 0.8104\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.3969 - acc: 0.8575\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 264us/sample - loss: 0.3577 - acc: 0.8706\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 245us/sample - loss: 0.3335 - acc: 0.8791\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 248us/sample - loss: 0.3152 - acc: 0.8842\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 250us/sample - loss: 0.2975 - acc: 0.8912\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 235us/sample - loss: 0.2856 - acc: 0.8954\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.2740 - acc: 0.8993\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 234us/sample - loss: 0.2635 - acc: 0.9034\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.2535 - acc: 0.9070\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 17s 320us/sample - loss: 0.5489 - acc: 0.8134\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 17s 315us/sample - loss: 0.3955 - acc: 0.8589\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 17s 307us/sample - loss: 0.3570 - acc: 0.8701\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 18s 342us/sample - loss: 0.3321 - acc: 0.8802\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 17s 322us/sample - loss: 0.3124 - acc: 0.8855\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 19s 350us/sample - loss: 0.2977 - acc: 0.8914\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 22s 416us/sample - loss: 0.2842 - acc: 0.8960\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 23s 430us/sample - loss: 0.2717 - acc: 0.8999\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 19s 354us/sample - loss: 0.2604 - acc: 0.9035\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 24s 439us/sample - loss: 0.2509 - acc: 0.9071\n"
     ]
    }
   ],
   "source": [
    "# Model3\n",
    "\n",
    "test_loss_list_model3 = []\n",
    "test_acc_list_model3 = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model3 \n",
    "    \n",
    "    # Redefine model\n",
    "    model3 = define_compile_model3()\n",
    "    \n",
    "    # Fit model\n",
    "    model3.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model3.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list_model3.append(test_loss)\n",
    "    test_acc_list_model3.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88514996\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model3 = np.mean(test_acc_list_model3)\n",
    "print('Accuracy:', CV_accuracy_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 45s 833us/sample - loss: 0.1072 - acc: 0.9646\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 32s 594us/sample - loss: 0.0646 - acc: 0.9764\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 47s 862us/sample - loss: 0.0573 - acc: 0.9790\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 32s 592us/sample - loss: 0.0520 - acc: 0.9810\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 33s 607us/sample - loss: 0.0477 - acc: 0.9825\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 32s 597us/sample - loss: 0.0464 - acc: 0.9832\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 39s 727us/sample - loss: 0.0414 - acc: 0.9842\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 31s 579us/sample - loss: 0.0415 - acc: 0.9847 - loss\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 46s 861us/sample - loss: 0.0379 - acc: 0.9858\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 47s 874us/sample - loss: 0.0372 - acc: 0.9864\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 44s 815us/sample - loss: 0.5155 - acc: 0.8144\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 42s 775us/sample - loss: 0.3804 - acc: 0.8609\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 60s 1ms/sample - loss: 0.3420 - acc: 0.8738\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 65s 1ms/sample - loss: 0.3146 - acc: 0.8845\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 37s 686us/sample - loss: 0.2958 - acc: 0.8893\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 33s 608us/sample - loss: 0.2824 - acc: 0.8943\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 29s 539us/sample - loss: 0.2697 - acc: 0.8988\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 26s 486us/sample - loss: 0.2596 - acc: 0.9022\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 407us/sample - loss: 0.2490 - acc: 0.9056\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 22s 402us/sample - loss: 0.2390 - acc: 0.9098\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 23s 423us/sample - loss: 0.5109 - acc: 0.8169\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 26s 483us/sample - loss: 0.3772 - acc: 0.8614\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 27s 500us/sample - loss: 0.3405 - acc: 0.8766\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 28s 517us/sample - loss: 0.3152 - acc: 0.8836\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 23s 422us/sample - loss: 0.3011 - acc: 0.8887\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 23s 421us/sample - loss: 0.2824 - acc: 0.8943\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 22s 404us/sample - loss: 0.2702 - acc: 0.9000\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 22s 412us/sample - loss: 0.2600 - acc: 0.9032\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 402us/sample - loss: 0.2455 - acc: 0.9078\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 22s 398us/sample - loss: 0.2403 - acc: 0.9095\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 22s 408us/sample - loss: 0.5365 - acc: 0.8062\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 21s 394us/sample - loss: 0.3838 - acc: 0.8589\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 28s 510us/sample - loss: 0.3447 - acc: 0.8721\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 22s 412us/sample - loss: 0.3180 - acc: 0.8826\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 23s 417us/sample - loss: 0.2982 - acc: 0.8890\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.2852 - acc: 0.8935\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 34s 620us/sample - loss: 0.2735 - acc: 0.8977\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 44s 816us/sample - loss: 0.2579 - acc: 0.9046\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 23s 424us/sample - loss: 0.2467 - acc: 0.9048\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 26s 478us/sample - loss: 0.2408 - acc: 0.9092\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 29s 532us/sample - loss: 0.5118 - acc: 0.8146\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 25s 459us/sample - loss: 0.3758 - acc: 0.8611\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 28s 518us/sample - loss: 0.3368 - acc: 0.8761\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 29s 541us/sample - loss: 0.3160 - acc: 0.8840\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 29s 531us/sample - loss: 0.2955 - acc: 0.8893\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 24s 442us/sample - loss: 0.2818 - acc: 0.8951\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 32s 597us/sample - loss: 0.2684 - acc: 0.8989\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 32s 596us/sample - loss: 0.2578 - acc: 0.9021\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 29s 537us/sample - loss: 0.2483 - acc: 0.9050\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 28s 525us/sample - loss: 0.2377 - acc: 0.9099\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 32s 595us/sample - loss: 0.5191 - acc: 0.8149\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 27s 501us/sample - loss: 0.3744 - acc: 0.8628\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 37s 684us/sample - loss: 0.3398 - acc: 0.8742\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 25s 471us/sample - loss: 0.3126 - acc: 0.8831\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.2967 - acc: 0.8896\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 23s 422us/sample - loss: 0.2797 - acc: 0.8952\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 22s 400us/sample - loss: 0.2668 - acc: 0.8990\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 23s 434us/sample - loss: 0.2557 - acc: 0.9020\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 24s 452us/sample - loss: 0.2451 - acc: 0.9062\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 22s 401us/sample - loss: 0.2361 - acc: 0.9095\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 31s 573us/sample - loss: 0.5127 - acc: 0.8175\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 22s 405us/sample - loss: 0.3791 - acc: 0.8608\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 22s 410us/sample - loss: 0.3415 - acc: 0.8735\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 22s 413us/sample - loss: 0.3166 - acc: 0.8808\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 23s 423us/sample - loss: 0.2978 - acc: 0.8891\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 23s 419us/sample - loss: 0.2830 - acc: 0.8941\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 26s 484us/sample - loss: 0.2704 - acc: 0.8979\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 26s 473us/sample - loss: 0.2616 - acc: 0.9018\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 399us/sample - loss: 0.2500 - acc: 0.9058\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 22s 413us/sample - loss: 0.2398 - acc: 0.9092\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 31s 579us/sample - loss: 0.5247 - acc: 0.8132\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 22s 413us/sample - loss: 0.3795 - acc: 0.8603\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 25s 460us/sample - loss: 0.3404 - acc: 0.8746\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 23s 422us/sample - loss: 0.3180 - acc: 0.8828\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 28s 521us/sample - loss: 0.2980 - acc: 0.8884\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 36s 669us/sample - loss: 0.2832 - acc: 0.8949\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 32s 590us/sample - loss: 0.2717 - acc: 0.8993\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 27s 506us/sample - loss: 0.2592 - acc: 0.9034\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 27s 504us/sample - loss: 0.2498 - acc: 0.9071\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 27s 505us/sample - loss: 0.2394 - acc: 0.9108\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 44s 823us/sample - loss: 0.5228 - acc: 0.8128\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 25s 464us/sample - loss: 0.3749 - acc: 0.8627\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 27s 502us/sample - loss: 0.3392 - acc: 0.8744\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 29s 539us/sample - loss: 0.3133 - acc: 0.8851\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 27s 507us/sample - loss: 0.2946 - acc: 0.8909\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 25s 460us/sample - loss: 0.2807 - acc: 0.8952\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 28s 510us/sample - loss: 0.2660 - acc: 0.9002\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 25s 468us/sample - loss: 0.2560 - acc: 0.9032\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 26s 483us/sample - loss: 0.2473 - acc: 0.9062\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 29s 530us/sample - loss: 0.2369 - acc: 0.9104\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 27s 494us/sample - loss: 0.5291 - acc: 0.8122\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 26s 473us/sample - loss: 0.3787 - acc: 0.8618\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 27s 506us/sample - loss: 0.3379 - acc: 0.8767\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 33s 607us/sample - loss: 0.3113 - acc: 0.8861\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 27s 502us/sample - loss: 0.2976 - acc: 0.8910\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 26s 478us/sample - loss: 0.2778 - acc: 0.8967\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.2678 - acc: 0.9005\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 26s 478us/sample - loss: 0.2529 - acc: 0.9056\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 26s 474us/sample - loss: 0.2427 - acc: 0.9096\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 26s 480us/sample - loss: 0.2367 - acc: 0.9124\n"
     ]
    }
   ],
   "source": [
    "# Model4\n",
    "\n",
    "test_loss_list_model4 = []\n",
    "test_acc_list_model4 = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model4 \n",
    "    \n",
    "    # Redefine model\n",
    "    model4 = define_compile_model4()\n",
    "    \n",
    "    # Fit model\n",
    "    model4.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model4.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list_model4.append(test_loss)\n",
    "    test_acc_list_model4.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88386667\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model4 = np.mean(test_acc_list_model4)\n",
    "print('Accuracy:', CV_accuracy_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 16s 305us/sample - loss: 0.1073 - acc: 0.9666\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 15s 282us/sample - loss: 0.0616 - acc: 0.9786\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 15s 276us/sample - loss: 0.0541 - acc: 0.9811\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 17s 314us/sample - loss: 0.0483 - acc: 0.9826\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 273us/sample - loss: 0.0446 - acc: 0.9837\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 18s 336us/sample - loss: 0.0419 - acc: 0.9849\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 225us/sample - loss: 0.0387 - acc: 0.9852\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.0362 - acc: 0.9863\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.0343 - acc: 0.9869\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.0332 - acc: 0.9877\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 249us/sample - loss: 0.5359 - acc: 0.8134\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s 212us/sample - loss: 0.4030 - acc: 0.8560\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.3624 - acc: 0.8690\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.3382 - acc: 0.8788\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 216us/sample - loss: 0.3225 - acc: 0.8824\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 220us/sample - loss: 0.3111 - acc: 0.8863\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.2941 - acc: 0.8936\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 234us/sample - loss: 0.2859 - acc: 0.8945\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.2800 - acc: 0.8966\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.2682 - acc: 0.9003\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 235us/sample - loss: 0.5339 - acc: 0.8120\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 12s 217us/sample - loss: 0.4046 - acc: 0.8556\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.3661 - acc: 0.8691\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.3429 - acc: 0.8758\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.3230 - acc: 0.8830\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 229us/sample - loss: 0.3087 - acc: 0.8864\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 16s 304us/sample - loss: 0.2957 - acc: 0.8915\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.2870 - acc: 0.8948\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 16s 295us/sample - loss: 0.2774 - acc: 0.8980\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 281us/sample - loss: 0.2681 - acc: 0.9018\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 16s 292us/sample - loss: 0.5310 - acc: 0.8136\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.4004 - acc: 0.8568\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 255us/sample - loss: 0.3627 - acc: 0.8689\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 15s 281us/sample - loss: 0.3407 - acc: 0.8758\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 17s 319us/sample - loss: 0.3236 - acc: 0.8832\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 19s 344us/sample - loss: 0.3071 - acc: 0.8872\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s 251us/sample - loss: 0.2949 - acc: 0.8907\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 237us/sample - loss: 0.2832 - acc: 0.8947\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.2755 - acc: 0.8988\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 246us/sample - loss: 0.2659 - acc: 0.9012\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 248us/sample - loss: 0.5293 - acc: 0.8152\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.3983 - acc: 0.8569\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 232us/sample - loss: 0.3576 - acc: 0.8715\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.3348 - acc: 0.8782\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 14s 259us/sample - loss: 0.3161 - acc: 0.8842\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.3010 - acc: 0.8893\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.2898 - acc: 0.8933\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 13s 233us/sample - loss: 0.2794 - acc: 0.8982\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 14s 253us/sample - loss: 0.2709 - acc: 0.9001\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 13s 233us/sample - loss: 0.2637 - acc: 0.9032\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 243us/sample - loss: 0.5227 - acc: 0.8163\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.3980 - acc: 0.8580\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 225us/sample - loss: 0.3577 - acc: 0.8711\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 240us/sample - loss: 0.3334 - acc: 0.8786\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.3146 - acc: 0.8846\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.2992 - acc: 0.8894\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.2899 - acc: 0.8928\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.2805 - acc: 0.8956\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 229us/sample - loss: 0.2710 - acc: 0.8999\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.2630 - acc: 0.9016\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 242us/sample - loss: 0.5271 - acc: 0.8170\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.3975 - acc: 0.8599\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 14s 254us/sample - loss: 0.3610 - acc: 0.8698\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 227us/sample - loss: 0.3361 - acc: 0.8773\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.3198 - acc: 0.8831\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 221us/sample - loss: 0.3049 - acc: 0.8886\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 229us/sample - loss: 0.2917 - acc: 0.8921\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.2831 - acc: 0.8949\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.2721 - acc: 0.8991\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 19s 361us/sample - loss: 0.2669 - acc: 0.9010\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 15s 277us/sample - loss: 0.5318 - acc: 0.8137\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 234us/sample - loss: 0.4001 - acc: 0.8568\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 222us/sample - loss: 0.3614 - acc: 0.8692\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 231us/sample - loss: 0.3377 - acc: 0.8774\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.3198 - acc: 0.8845\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s 234us/sample - loss: 0.3072 - acc: 0.8879\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.2950 - acc: 0.8911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 213us/sample - loss: 0.2846 - acc: 0.8958 - loss: 0.2845 - acc: 0.895\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 216us/sample - loss: 0.2752 - acc: 0.8985\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.2639 - acc: 0.9016\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 20s 365us/sample - loss: 0.5283 - acc: 0.8153\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 16s 293us/sample - loss: 0.4066 - acc: 0.8560\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 227us/sample - loss: 0.3674 - acc: 0.8681\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 216us/sample - loss: 0.3406 - acc: 0.8760\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 12s 228us/sample - loss: 0.3223 - acc: 0.8826\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 12s 224us/sample - loss: 0.3078 - acc: 0.8885\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 12s 214us/sample - loss: 0.2966 - acc: 0.8921\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 12s 218us/sample - loss: 0.2845 - acc: 0.8961\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 12s 216us/sample - loss: 0.2760 - acc: 0.8977\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 0.2685 - acc: 0.9022\n",
      "Train on 54000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 241us/sample - loss: 0.5304 - acc: 0.8165\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 247us/sample - loss: 0.3992 - acc: 0.8585\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.3585 - acc: 0.8710\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 12s 223us/sample - loss: 0.3346 - acc: 0.8779\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 244us/sample - loss: 0.3140 - acc: 0.8856\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 15s 274us/sample - loss: 0.3006 - acc: 0.8903\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 11s 211us/sample - loss: 0.2878 - acc: 0.8945\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 11s 201us/sample - loss: 0.2766 - acc: 0.8978\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 18s 332us/sample - loss: 0.2707 - acc: 0.9000\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s 256us/sample - loss: 0.2609 - acc: 0.9037\n"
     ]
    }
   ],
   "source": [
    "# Model5\n",
    "\n",
    "test_loss_list_model5 = []\n",
    "test_acc_list_model5 = []\n",
    "\n",
    "for k in range(10):\n",
    "    \n",
    "    # Pick our training and test set needed for the CV procedure\n",
    "    testCVim = train_images[CVin[k][0]]\n",
    "    testCVlb = train_labels[CVin[k][0]]\n",
    "    trainCVim = train_images[CVin[k][1]]\n",
    "    trainCVlb = train_labels[CVin[k][1]]\n",
    "    \n",
    "    # Delete the old model\n",
    "    del model5 \n",
    "    \n",
    "    # Redefine model\n",
    "    model5 = define_compile_model5()\n",
    "    \n",
    "    # Fit model\n",
    "    model5.fit(trainCVim, trainCVlb, epochs = 10)\n",
    "    test_loss, test_acc = model5.evaluate(testCVim, testCVlb, verbose = 0)\n",
    "    \n",
    "    # Record the results in our lists\n",
    "    test_loss_list_model5.append(test_loss)\n",
    "    test_acc_list_model5.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8797167\n"
     ]
    }
   ],
   "source": [
    "CV_accuracy_model5 = np.mean(test_acc_list_model5)\n",
    "print('Accuracy:', CV_accuracy_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison\n",
    "Next I'll check which of the models perform best. It can also be interesting to plot the accuracy against number of hidden layers and number of parameters, just to see if there seems to be any patterns there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = [CV_accuracy_model,\n",
    "     CV_accuracy_model1,\n",
    "     CV_accuracy_model2,\n",
    "     CV_accuracy_model3,\n",
    "     CV_accuracy_model4,\n",
    "     CV_accuracy_model5]\n",
    "\n",
    "x = ['Original model',\n",
    "    'Model 1',\n",
    "    'Model 2',\n",
    "    'Model 3',\n",
    "    'Model 4',\n",
    "    'Model 5']\n",
    "\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856999"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wasn't very clear which one had highest accuracy from the plot\n",
    "\n",
    "# Checking highest accuracy\n",
    "max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd70a58780>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the model accuracy against number of layers\n",
    "x = sorted([len(model.layers), \n",
    "     len(model1.layers), \n",
    "     len(model2.layers),\n",
    "     len(model3.layers),\n",
    "     len(model4.layers),\n",
    "     len(model5.layers)])\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbd70b9d0f0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the model accuracy against number of parameters\n",
    "x = sorted([model.count_params(),\n",
    "    model1.count_params(),\n",
    "    model2.count_params(),\n",
    "    model3.count_params(),\n",
    "    model4.count_params(),\n",
    "    model5.count_params()])\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "It appears that all models are performing very similarly. The original model is performing a tiny bit better than the rest, so I'll proceed with this one. There also doesn't seem to be a clear patterns on the relation between number of parameters or number of layers on the cross validation accuracy score of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4:\n",
    "\n",
    "Train the selected networks on the entire training data. Then test its performance on the testing data set and summariaze the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 27s 456us/sample - loss: 0.4975 - acc: 0.8254\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 29s 488us/sample - loss: 0.3795 - acc: 0.8632\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 0.3406 - acc: 0.8771\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 381us/sample - loss: 0.3161 - acc: 0.8835\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.2971 - acc: 0.8909\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 275us/sample - loss: 0.2839 - acc: 0.8951\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 307us/sample - loss: 0.2727 - acc: 0.8996\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 19s 310us/sample - loss: 0.2629 - acc: 0.9021\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 304us/sample - loss: 0.2503 - acc: 0.9067\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 368us/sample - loss: 0.2406 - acc: 0.9093\n",
      "Accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "# Fit model on all training data\n",
    "model.fit(train_images, train_labels, epochs = 10)\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 0)\n",
    "\n",
    "# Print results\n",
    "print('Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check predictions so we can evaluate performance per class\n",
    "predictions = model.predict_classes(test_images, verbose = 0)\n",
    "\n",
    "# Check 5 first\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for T-shirt/top is 0.18\n",
      "Error rate for Trouser is 0.02\n",
      "Error rate for Pullover is 0.15\n",
      "Error rate for Dress is 0.17\n",
      "Error rate for Coat is 0.29\n",
      "Error rate for Sandal is 0.04\n",
      "Error rate for Shirt is 0.27\n",
      "Error rate for Sneaker is 0.04\n",
      "Error rate for Bag is 0.03\n",
      "Error rate for Ankle boot is 0.03\n"
     ]
    }
   ],
   "source": [
    "# Specify class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Check error rate per clothing item\n",
    "item_error_rate = []\n",
    "for i in range(10):\n",
    "    item_index = test_labels == i\n",
    "    item_predictions = predictions[item_index]\n",
    "    item_true = test_labels[item_index]\n",
    "    error_rate_item = 1 - np.mean(item_true == item_predictions)\n",
    "    item_error_rate.append(error_rate_item)\n",
    "\n",
    "for i in range(10):\n",
    "    print('Error rate for', class_names[i], 'is', np.round(item_error_rate[i], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: We can see that the model is doing a rather bad job on shirt, which is surprising because it's exactly what the Gaussian classification model was bad at too. On the other hand it is extremely good at classifying trousers, only 2 % are classified as something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsoS7CPDCaXH"
   },
   "source": [
    "### Task 5: \n",
    "With the models trained, you can use them to make predictions about some images. Below you see a discussion of predictions based on the original model. Please, complement it with an analogous discussion for the best model out of five you have trained in the cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: Ok so apparently I rushed ahead :) What we're going to look at next is the class probabilities. These we get if we use predict() instead of predict_class(). They are interesting beause they can be used to see how sure the model is of it's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.5026788e-07, 1.4786889e-11, 6.9921997e-09, 2.2275459e-10,\n",
       "       3.7037548e-08, 2.7212743e-03, 4.5314446e-06, 2.1103183e-02,\n",
       "       1.8585896e-06, 9.7616857e-01], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at first prediction\n",
    "prediction_prob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "A prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different articles of clothing. You can see which label has the highest confidence value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest value \n",
    "prediction_prob[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: The first prediction that the image classified is an ankle boot (index 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygh2yYC972ne"
   },
   "source": [
    "Graph this to inspect the full set of 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "# Defining a function with which we can inspect images\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.imshow(img, cmap = plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                        100*np.max(predictions_array),\n",
    "                                        class_names[true_label]),\n",
    "              color = color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function with which we can plot the prob array\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color = \"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, prediction_prob[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, prediction_prob[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: As we can see above, the classifier is quite good at guessing which item is which. For the shirt on the second row in the middle column, it was quite unsure but still classified it right. This is in line with our other findings - that the shirts are the hardest to classify. Another example like this is the sneaker in the bottom left corner, which was hard to classify despite the fact that the algorithm is generally good at classifying sneakers. An idea for this is that this shoe is turned in the opposite direction than the others, and that the classifier is sensitive to this kind of setting. That actually illustrates the problems with deep learning a little bit - sometimes our algorithms learns different patterns that what we want it to. Maybe it learns that a shoe has a tip to the left, while we as humans knows that a shoe is a shoe no matter what directions it's tip is pointing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6:\n",
    "Take the reduced data set (16 x 16) from the previous lab and choose the best neural network based on the performance on the full data. Assess the performance of this network on this data set and compare with the MGaussianLikelihood method assessed in the previous lab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reshaping function\n",
    "def dim_reduction(original_matrix, new_dim):\n",
    "    # Checking how many observations to go through\n",
    "    nr_observations = len(original_matrix)\n",
    "    \n",
    "    # Creating empty matrix of the wanted form\n",
    "    merged_matrix = np.zeros((nr_observations, new_dim, new_dim))\n",
    "    \n",
    "    # Creating variable to use when we loop over the matrices\n",
    "    multiplier = np.int(28/new_dim)\n",
    "    \n",
    "    # Looping over observations and merging\n",
    "    for nr in range(nr_observations):\n",
    "        for i in range(len(merged_matrix[0])):\n",
    "            for j in range(len(merged_matrix[0])):\n",
    "                merged_matrix[nr, i, j] = np.mean(original_matrix[nr, (multiplier*i):(multiplier*i+multiplier),(multiplier*j):(multiplier*j+multiplier)])\n",
    "                \n",
    "    return merged_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_16 = dim_reduction(train_images, 4)\n",
    "test_images_16 = dim_reduction(test_images, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 407us/sample - loss: 0.9406 - acc: 0.6766\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.7242 - acc: 0.7269\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 0.6905 - acc: 0.7385\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 22s 362us/sample - loss: 0.6646 - acc: 0.7496\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 342us/sample - loss: 0.6444 - acc: 0.7562\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 349us/sample - loss: 0.6284 - acc: 0.7626\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.6163 - acc: 0.7676\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 21s 350us/sample - loss: 0.6055 - acc: 0.7703\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.5966 - acc: 0.7746\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.5892 - acc: 0.7776\n"
     ]
    }
   ],
   "source": [
    "# Set up first model again\n",
    "\n",
    "# Set up the model using two hidden layers\n",
    "model_16 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (4, 4)),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# Set up compilation\n",
    "model_16.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model_16.fit(train_images_16, train_labels, epochs = 10)\n",
    "\n",
    "# Test model\n",
    "test_loss_16, test_acc_16 = model_16.evaluate(test_images_16, test_labels, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: Since this is a little bit tedious to define again and again, I'll make use of the functions I've made above to do it all in once. Will be interesting to see how long it takes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluation(model_nr, train_data, train_labs, test_data, test_labs):\n",
    "    # Define and compile model\n",
    "    if model_nr == 1:\n",
    "        model = define_compile_model1(dim = 4)\n",
    "    elif model_nr == 2:\n",
    "        model = define_compile_model2(dim = 4)\n",
    "    elif model_nr == 3:\n",
    "        model = define_compile_model3(dim = 4)\n",
    "    elif model_nr == 4:\n",
    "        model = define_compile_model4(dim = 4)\n",
    "    elif model_nr == 5:\n",
    "        model = define_compile_model5(dim = 4)\n",
    "    else:\n",
    "        print('Theres no model with this number.')\n",
    "    \n",
    "    # Fit model on all training data\n",
    "    model.fit(train_data, train_labs, epochs = 10)\n",
    "\n",
    "    # Evaluate model on test data\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labs, verbose = 0)\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.8123 - acc: 0.6978\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 315us/sample - loss: 0.6566 - acc: 0.7498\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 276us/sample - loss: 0.6155 - acc: 0.7641\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 313us/sample - loss: 0.5864 - acc: 0.7760\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s 372us/sample - loss: 0.5658 - acc: 0.7846\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 20s 339us/sample - loss: 0.5507 - acc: 0.7903\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 19s 318us/sample - loss: 0.5358 - acc: 0.7973\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 374us/sample - loss: 0.5263 - acc: 0.7987\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.5164 - acc: 0.8022\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 20s 331us/sample - loss: 0.5070 - acc: 0.8065\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.9229 - acc: 0.6471\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 270us/sample - loss: 0.6966 - acc: 0.7308\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 314us/sample - loss: 0.6598 - acc: 0.7451\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.6376 - acc: 0.7557\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 297us/sample - loss: 0.6189 - acc: 0.7633\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.6027 - acc: 0.7703\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 305us/sample - loss: 0.5891 - acc: 0.7762\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 398us/sample - loss: 0.5796 - acc: 0.7786\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 25s 420us/sample - loss: 0.5689 - acc: 0.7829\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 284us/sample - loss: 0.5606 - acc: 0.7862\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 1.3557 - acc: 0.5752\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 0.8453 - acc: 0.6952\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 266us/sample - loss: 0.7741 - acc: 0.7115\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 279us/sample - loss: 0.7484 - acc: 0.7189\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 355us/sample - loss: 0.7333 - acc: 0.7235\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 303us/sample - loss: 0.7216 - acc: 0.7288\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 15s 257us/sample - loss: 0.7122 - acc: 0.7309\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.7033 - acc: 0.7344\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 213us/sample - loss: 0.6963 - acc: 0.7378\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.6891 - acc: 0.7393\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 22s 363us/sample - loss: 0.8000 - acc: 0.6915\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 22s 374us/sample - loss: 0.6362 - acc: 0.7551\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 22s 362us/sample - loss: 0.5914 - acc: 0.7742\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 21s 356us/sample - loss: 0.5624 - acc: 0.7848\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 347us/sample - loss: 0.5404 - acc: 0.7941\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 21s 358us/sample - loss: 0.5262 - acc: 0.8000\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 389us/sample - loss: 0.5135 - acc: 0.8039\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 406us/sample - loss: 0.5017 - acc: 0.8069\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 437us/sample - loss: 0.4927 - acc: 0.8114\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 27s 453us/sample - loss: 0.4861 - acc: 0.8139\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 1.0153 - acc: 0.6640\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.7433 - acc: 0.7226\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.7094 - acc: 0.7320\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.6870 - acc: 0.7407\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.6707 - acc: 0.7476\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 161us/sample - loss: 0.6578 - acc: 0.7523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.6465 - acc: 0.7571\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.6374 - acc: 0.7595\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 161us/sample - loss: 0.6280 - acc: 0.7646\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 0.6213 - acc: 0.7656\n",
      "CPU times: user 17min 40s, sys: 5min 6s, total: 22min 46s\n",
      "Wall time: 15min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Evaluating all five models but now on lower dimensions\n",
    "accuracy_list = []\n",
    "accuracy_list.append(test_acc_16)\n",
    "\n",
    "for i in range(5):\n",
    "    model_number = i + 1\n",
    "    test_acc = evaluation(model_number, train_images_16, train_labels, test_images_16, test_labels)\n",
    "    accuracy_list.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model nr 1 was: 0.7729\n",
      "Accuracy for model nr 2 was: 0.7998\n",
      "Accuracy for model nr 3 was: 0.7756\n",
      "Accuracy for model nr 4 was: 0.7327\n",
      "Accuracy for model nr 5 was: 0.8051\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Accuracy for model nr', i+1, 'was:', accuracy_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment*: The Gaussian model we trained on four dimensional data had an error rate of about 30% (at least in my case). The error rate for this neural network classifier is lower, at around 20%, so it clearly performs better. However, we can note that the error rate is higher for the low-dimensional data than it was for the data with higher dimension. This is because of the neural networks ability to deal with and take advantage of high-dimensional data. Furthermore, with our high-dimensional data the original model was best, but with lower dimension model5 was the best instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grader box: \n",
    "\n",
    "In what follows the grader will put the values according the following check list:\n",
    "\n",
    "* 1 Have all commands included in a raw notebook been evaluated? (0 or 0.5pt)\n",
    "* 2 Have all commands been experimented with? (0 or 0.5pt)\n",
    "* 3 Have all experiments been briefly commented? (0 or 0.5pt)\n",
    "* 4 Have all tasks been attempted? (0, 0.5, or 1pt)\n",
    "* 5 How many of the tasks have been completed? (0, 0.5, or 1pt)\n",
    "* 6 How many of the tasks (completed or not) have been commented? (0, 0.5, or 1pt)\n",
    "* 7 Have been the conclusions from performing the tasks clearly stated? (0, 0.5, or 1pt)\n",
    "* 8 Have been the overall organization of the submitted Lab notebook been neat and easy to follow by the grader? (0, or 0.5pt) \n",
    "\n",
    "\n",
    "#### 1 Have all commands included in a raw notebook been evaluated? (0 or 0.5pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 2 Have all commands been experimented with? (0 or 0.5pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 3 Have all experiments been briefly commented? (0 or 0.5pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 4 Have all tasks been attempted? (0, 0.5, or 1pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 5 How many of the tasks have been completed? (0, 0.5, or 1pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 6 How many of the tasks (completed or not) have been commented? (0, 0.5, or 1pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 7 Have been the conclusions from performing the tasks clearly stated? (0, 0.5, or 1pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "#### 8 Have been the overall organization of the submitted Lab notebook been neat and easy to follow by the grader? (0, or 0.5pt)\n",
    "\n",
    "#### Grader's comment (if desired): \n",
    "N/A\n",
    "\n",
    "### Overall score\n",
    "\n",
    "### Score and grader's comment (if desired): \n",
    "N/A"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
